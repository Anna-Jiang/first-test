% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}

\usepackage{babel}
\usepackage{times}
\usepackage[Sonny]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}


\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }



\title{legonet Documentation}
\date{May 27, 2016}
\release{}
\author{Author}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\setcounter{tocdepth}{3}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{legonet package}
\label{legonet:legonet-package}\label{legonet:welcome-to-legonet-s-documentation}\label{legonet::doc}

\section{Submodules}
\label{legonet:submodules}

\section{legonet.activations module}
\label{legonet:module-legonet.activations}\label{legonet:legonet-activations-module}\index{legonet.activations (module)}
Created on Sat Apr 23 15:55:04 2016

@author: lifu
\index{get() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.get}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{get}}{\emph{name}}{}
Return activation according to name.
\begin{description}
\item[{Args:}] \leavevmode
name: name of activation function.

\item[{Returns:}] \leavevmode
the activation according to \emph{name}.

\end{description}

\end{fulllineitems}

\index{identity() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.identity}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{identity}}{\emph{x}}{}
Return the input tensor without any change.
\begin{description}
\item[{Args:}] \leavevmode
x: Input tensor.

\item[{Returns:}] \leavevmode
The input tensor.

\end{description}

\end{fulllineitems}

\index{relu() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.relu}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{relu}}{\emph{x}}{}
Compute the rectified linear of x.
\begin{description}
\item[{Args:}] \leavevmode
x: Input tensor.

\item[{Returns:}] \leavevmode
A \emph{Tensor} of same shape as \emph{x}.

\end{description}

\end{fulllineitems}

\index{sigmoid() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.sigmoid}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{sigmoid}}{\emph{x}}{}
Compute the sigmoid of x.
\begin{description}
\item[{Args:}] \leavevmode
x: Input tensor.

\item[{Returns:}] \leavevmode
A \emph{Tensor} of same shape as \emph{x}.

\end{description}

\end{fulllineitems}

\index{softmax() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.softmax}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{softmax}}{\emph{x}}{}
Compute the softmax of x.
\begin{description}
\item[{Args:}] \leavevmode
x: Input tensor.

\item[{Returns:}] \leavevmode
A \emph{Tensor} of same shape as \emph{x}.

\end{description}

\end{fulllineitems}

\index{tanh() (in module legonet.activations)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.activations.tanh}\pysiglinewithargsret{\code{legonet.activations.}\bfcode{tanh}}{\emph{x}}{}
Compute the hyperbolic tangent of x.
\begin{description}
\item[{Args:}] \leavevmode
x: Input tensor.

\item[{Returns:}] \leavevmode
A \emph{Tensor} of same shape as \emph{x}.

\end{description}

\end{fulllineitems}



\section{legonet.initializers module}
\label{legonet:legonet-initializers-module}\label{legonet:module-legonet.initializers}\index{legonet.initializers (module)}
Created on Sat Apr 23 16:10:50 2016

@author: lifu
\index{get() (in module legonet.initializers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.initializers.get}\pysiglinewithargsret{\code{legonet.initializers.}\bfcode{get}}{\emph{name}}{}
Return an array filler according to name.
\begin{description}
\item[{Args:}] \leavevmode
name: the name of initializer.

\item[{Returns:}] \leavevmode
the initializer corresponding to \emph{name}.

\end{description}

\end{fulllineitems}



\section{legonet.layers module}
\label{legonet:module-legonet.layers}\label{legonet:legonet-layers-module}\index{legonet.layers (module)}
Created on Sat Apr 23 23:17:39 2016

@author: lifu
\index{Convolution (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Convolution}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{Convolution}}{\emph{filter\_shape}, \emph{n\_output\_channels}, \emph{activation\_fn='relu'}, \emph{strides=None}, \emph{padding='SAME'}, \emph{weight\_init=None}, \emph{bias\_init=None}, \emph{weight\_regularizer=None}, \emph{bias\_regularizer=None}, \emph{use\_cudnn\_on\_gpu=True}, \emph{has\_bias=True}, \emph{name=None}, \emph{trainable=True}}{}
Bases: {\hyperref[legonet:legonet.layers.Layer]{\emph{\code{legonet.layers.Layer}}}}

Convolution layer for 2D arrays.
\index{call() (legonet.layers.Convolution method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Convolution.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow}}{}
Construct the layer in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: The input tensor

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Embedding (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Embedding}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{Embedding}}{\emph{input\_shape}, \emph{init\_values}, \emph{name=None}, \emph{trainable=True}}{}
Bases: {\hyperref[legonet:legonet.layers.Layer]{\emph{\code{legonet.layers.Layer}}}}

Embedding layer.
\index{call() (legonet.layers.Embedding method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Embedding.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow=None}}{}
Construct the layer in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: Deprecated, will be ignored. (Default value = None)

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{FullyConnected (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.FullyConnected}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{FullyConnected}}{\emph{n\_output\_units}, \emph{activation\_fn=None}, \emph{weight\_init=None}, \emph{bias\_init=None}, \emph{weight\_regularizer=None}, \emph{bias\_regularizer=None}, \emph{has\_bias=True}, \emph{name=None}, \emph{trainable=True}}{}
Bases: {\hyperref[legonet:legonet.layers.Layer]{\emph{\code{legonet.layers.Layer}}}}

A simple fully connected feedforward layer.
\index{call() (legonet.layers.FullyConnected method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.FullyConnected.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow}}{}
Construct the layer in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: The input tensor.

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Input (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Input}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{Input}}{\emph{input\_shape}, \emph{input\_dtype=tf.float32}, \emph{name=None}}{}
Bases: {\hyperref[legonet:legonet.layers.Layer]{\emph{\code{legonet.layers.Layer}}}}

Input layer.
\index{call() (legonet.layers.Input method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Input.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow=None}}{}
Construct the layer in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: Deprecated, will be ignored. (Default value = None)

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Layer (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Layer}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{Layer}}{\emph{name=None}, \emph{trainable=True}}{}
Bases: {\hyperref[legonet:legonet.topology.Node]{\emph{\code{legonet.topology.Node}}}}

Abstract base class for all kinds of layers.

This class is an abstract base class and is intended to be used only as an
interface for its derived classes. So, do not directly use it in neural
network.
\index{call() (legonet.layers.Layer method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Layer.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow}}{}
Construct the Layer in tensorflow graph.

This method is intended to be implemented in derived classes.
\begin{description}
\item[{Args:}] \leavevmode
flow: The input tensor.

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Pooling (class in legonet.layers)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Pooling}\pysiglinewithargsret{\strong{class }\code{legonet.layers.}\bfcode{Pooling}}{\emph{pool\_shape=None}, \emph{strides=None}, \emph{mode='max'}, \emph{padding='VALID'}, \emph{name=None}}{}
Bases: {\hyperref[legonet:legonet.layers.Layer]{\emph{\code{legonet.layers.Layer}}}}

Pooling layer for 2D arrays.
\index{call() (legonet.layers.Pooling method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.layers.Pooling.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow}}{}
Construct the layer in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: The input tensor.

\item[{Returns:}] \leavevmode
Output of this layer.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\section{legonet.models module}
\label{legonet:module-legonet.models}\label{legonet:legonet-models-module}\index{legonet.models (module)}
Created on Sat Apr 23 16:09:59 2016

@author: lifu
\index{NeuralNetwork (class in legonet.models)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork}\pysiglinewithargsret{\strong{class }\code{legonet.models.}\bfcode{NeuralNetwork}}{\emph{optimizer}, \emph{log\_dir=None}, \emph{output\_fn='softmax'}, \emph{loss\_fn='sparse\_softmax\_cross\_entropy'}, \emph{target\_dtype=tf.int64}, \emph{model=None}, \emph{graph=None}, \emph{session=None}}{}
Bases: \code{object}

Base classes of all neural networks.
\index{add() (legonet.models.NeuralNetwork method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork.add}\pysiglinewithargsret{\bfcode{add}}{\emph{layer}}{}
Add a layer to the model inside this NeuralNetwork.
\begin{description}
\item[{Args:}] \leavevmode
layer: a Layer instance

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}

\index{build() (legonet.models.NeuralNetwork method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork.build}\pysiglinewithargsret{\bfcode{build}}{}{}
Construct the whole neural network in tensorflow graph.

\end{fulllineitems}

\index{fit() (legonet.models.NeuralNetwork method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork.fit}\pysiglinewithargsret{\bfcode{fit}}{\emph{x}, \emph{y}, \emph{n\_epochs=5}, \emph{batch\_size=32}, \emph{checkpoint\_dir=None}, \emph{randomized=True}, \emph{freq\_log=100}, \emph{freq\_checkpoint=10000}, \emph{loss\_decay=0.0}}{}
Train this model using x and y.
\begin{description}
\item[{Args:}] \leavevmode
x: Input array.
y: Targets array, should be consistent with target\_dtype.
n\_epochs: Number of epochs to iterate. (Default value = 5)
batch\_size: Size of mini-batch. (Default value = 32)
checkpoint\_dir: Path to the folder to store checkpoint files. (Default value = None)
randomized: Indicates whether use select mini-batch randomly. (Default value = True)
freq\_log: The frequency of logging. (Default value = 100)
freq\_checkpoint: The frequency of saving parameters to checkpoint files. (Default value = 10000)
loss\_decay: The decay rate used for displaying exponential moving average of loss. (Default value = 0.0)

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}

\index{load\_checkpoint() (legonet.models.NeuralNetwork method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork.load_checkpoint}\pysiglinewithargsret{\bfcode{load\_checkpoint}}{\emph{path=None}}{}
Load checkpoint from a file or directory.
\begin{description}
\item[{Args:}] \leavevmode
path: Path of folder containing checkpoint files. (Default value = None)

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}

\index{predict() (legonet.models.NeuralNetwork method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.models.NeuralNetwork.predict}\pysiglinewithargsret{\bfcode{predict}}{\emph{x}}{}
Output result given input.
\begin{description}
\item[{Args:}] \leavevmode
x: Input array.

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\section{legonet.objectives module}
\label{legonet:module-legonet.objectives}\label{legonet:legonet-objectives-module}\index{legonet.objectives (module)}
Created on Sat Apr 23 16:09:59 2016

@author: lifu
\index{get() (in module legonet.objectives)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.objectives.get}\pysiglinewithargsret{\code{legonet.objectives.}\bfcode{get}}{\emph{name}}{}
Return loss according to name.
\begin{description}
\item[{Args:}] \leavevmode
name: The name of the loss function.

\item[{Returns:}] \leavevmode
The loss function corresponding to \emph{name}.

\end{description}

\end{fulllineitems}

\index{mean\_square() (in module legonet.objectives)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.objectives.mean_square}\pysiglinewithargsret{\code{legonet.objectives.}\bfcode{mean\_square}}{\emph{output}, \emph{targets}}{}
Mean square error.
\begin{description}
\item[{Args:}] \leavevmode
output: The output \emph{Tensor} of model.
targets: A \emph{Tensor} of the same size as \emph{output}.

\item[{Returns:}] \leavevmode
A scalar indicating the mean-square error.

\end{description}

\end{fulllineitems}

\index{sigmoid\_cross\_entropy() (in module legonet.objectives)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.objectives.sigmoid_cross_entropy}\pysiglinewithargsret{\code{legonet.objectives.}\bfcode{sigmoid\_cross\_entropy}}{\emph{logits}, \emph{targets}}{}
Cross-entropy error for sigmoid output layer.
\begin{description}
\item[{Args:}] \leavevmode
logits: The \emph{Tensor} passed to logistic function.
targets: A \emph{Tensor} of the same shape as \emph{logits}.

\item[{Returns:}] \leavevmode
A scalar indicating the cross-entropy error.

\end{description}

\end{fulllineitems}

\index{softmax\_cross\_entropy() (in module legonet.objectives)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.objectives.softmax_cross_entropy}\pysiglinewithargsret{\code{legonet.objectives.}\bfcode{softmax\_cross\_entropy}}{\emph{logits}, \emph{labels}}{}
Cross-entropy error for softmax output layer.
\begin{description}
\item[{Args:}] \leavevmode
logits: Unscaled log probabilities.
labels: Each row must be a valid probability distribution.

\item[{Returns:}] \leavevmode
A scalar indicating the cross-entropy error.

\end{description}

\end{fulllineitems}

\index{sparse\_softmax\_cross\_entropy() (in module legonet.objectives)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.objectives.sparse_softmax_cross_entropy}\pysiglinewithargsret{\code{legonet.objectives.}\bfcode{sparse\_softmax\_cross\_entropy}}{\emph{logits}, \emph{labels}}{}
Cross-entropy error for softmax output layer with one-hot target.
\begin{description}
\item[{Args:}] \leavevmode
logits: Unscaled log probabilities.
labels: Each element must be a class index.

\item[{Returns:}] \leavevmode
A scalar indicating the cross-entropy error.

\end{description}

\end{fulllineitems}



\section{legonet.optimizers module}
\label{legonet:module-legonet.optimizers}\label{legonet:legonet-optimizers-module}\index{legonet.optimizers (module)}
Created on Mon Apr 25 12:17:32 2016

@author: lifu


\section{legonet.regularizers module}
\label{legonet:module-legonet.regularizers}\label{legonet:legonet-regularizers-module}\index{legonet.regularizers (module)}
Created on Sat Apr 30 15:41:04 2016

@author: lifu


\section{legonet.topology module}
\label{legonet:legonet-topology-module}\label{legonet:module-legonet.topology}\index{legonet.topology (module)}
Created on Tue May 17 11:12:10 2016

@author: lifu
\index{Node (class in legonet.topology)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Node}\pysiglinewithargsret{\strong{class }\code{legonet.topology.}\bfcode{Node}}{\emph{name=None}}{}
Bases: \code{object}

Base class for all elements in graph.
\index{call() (legonet.topology.Node method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Node.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow}}{}
Construct the Node in tensorflow graph.
\begin{description}
\item[{Args:}] \leavevmode
flow: The input \emph{Tensor} to this \emph{Node}.

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Parallel (class in legonet.topology)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Parallel}\pysiglinewithargsret{\strong{class }\code{legonet.topology.}\bfcode{Parallel}}{\emph{name=None}, \emph{mode='concat'}, \emph{along\_dim=None}}{}
Bases: {\hyperref[legonet:legonet.topology.Node]{\emph{\code{legonet.topology.Node}}}}

Container Node whose inner nodes are in a parallel layout.
\index{add() (legonet.topology.Parallel method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Parallel.add}\pysiglinewithargsret{\bfcode{add}}{\emph{node}}{}
Add a \emph{Node} to this network.
\begin{description}
\item[{Args:}] \leavevmode
node: A \emph{Node} object.

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}

\index{call() (legonet.topology.Parallel method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Parallel.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow=None}}{}
Construct the Sequential and its nodes.
\begin{description}
\item[{Args:}] \leavevmode
flow: Input \emph{Tensor} object. (Default value = None)

\item[{Returns:}] \leavevmode
Output of this \emph{Node}.

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{Sequential (class in legonet.topology)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Sequential}\pysiglinewithargsret{\strong{class }\code{legonet.topology.}\bfcode{Sequential}}{\emph{name=None}}{}
Bases: {\hyperref[legonet:legonet.topology.Node]{\emph{\code{legonet.topology.Node}}}}

Container Node whose inner nodes are in a sequential layout.
\index{add() (legonet.topology.Sequential method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Sequential.add}\pysiglinewithargsret{\bfcode{add}}{\emph{node}}{}
Add a node to this network.
\begin{description}
\item[{Args:}] \leavevmode
node: A \emph{Node} object.

\item[{Returns:}] \leavevmode
None

\end{description}

\end{fulllineitems}

\index{call() (legonet.topology.Sequential method)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.topology.Sequential.call}\pysiglinewithargsret{\bfcode{call}}{\emph{flow=None}}{}
Construct the Sequential and its \emph{Node} s.
\begin{description}
\item[{Args:}] \leavevmode
flow: Input \emph{Tensor} object. (Default value = None)

\item[{Returns:}] \leavevmode
Output of this \emph{Node}.

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\section{Module contents}
\label{legonet:module-legonet}\label{legonet:module-contents}\index{legonet (module)}
Created on Sat Apr 23 16:09:59 2016

@author: lifu
\index{GraphKeys (class in legonet)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.GraphKeys}\pysigline{\strong{class }\code{legonet.}\bfcode{GraphKeys}}
Standard names to use for graph collections.
\index{MODEL\_INPUTS (legonet.GraphKeys attribute)}

\begin{fulllineitems}
\phantomsection\label{legonet:legonet.GraphKeys.MODEL_INPUTS}\pysigline{\bfcode{MODEL\_INPUTS}\strong{ = `model\_inputs'}}
\end{fulllineitems}


\end{fulllineitems}



\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\DUspan{xref,std,std-ref}{genindex}

\item {} 
\DUspan{xref,std,std-ref}{modindex}

\item {} 
\DUspan{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{l}
\item {\texttt{legonet}}, \pageref{legonet:module-legonet}
\item {\texttt{legonet.activations}}, \pageref{legonet:module-legonet.activations}
\item {\texttt{legonet.initializers}}, \pageref{legonet:module-legonet.initializers}
\item {\texttt{legonet.layers}}, \pageref{legonet:module-legonet.layers}
\item {\texttt{legonet.models}}, \pageref{legonet:module-legonet.models}
\item {\texttt{legonet.objectives}}, \pageref{legonet:module-legonet.objectives}
\item {\texttt{legonet.optimizers}}, \pageref{legonet:module-legonet.optimizers}
\item {\texttt{legonet.regularizers}}, \pageref{legonet:module-legonet.regularizers}
\item {\texttt{legonet.topology}}, \pageref{legonet:module-legonet.topology}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
